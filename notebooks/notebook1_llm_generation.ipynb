{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f018c1f",
   "metadata": {},
   "source": [
    "# Part 1: Generating a Diverse LLM Corpus for Frequency Analysis\n",
    "## Session 1: From LLM Generation to Word Frequency (45 minutes)\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Generate a diverse text corpus using an LLM to mirror the vocabulary found in large-scale datasets like the English Crowdsourcing Project (ECP).\n",
    "- Understand how prompt engineering across different genres (news, technical, fiction) can create a representative word frequency list.\n",
    "- Calculate word frequencies from the generated text to create a custom `llm_frequency` predictor.\n",
    "- Export the frequency data for comparative analysis in the next session.\n",
    "\n",
    "**Session Structure:**\n",
    "- **Setup & API Configuration** (10 minutes)\n",
    "- **Diverse Corpus Generation** (25 minutes)\n",
    "- **Frequency Calculation & Export** (10 minutes)\n",
    "\n",
    "---\n",
    "\n",
    "💡 **Research Context:** Our goal is to create a high-quality `llm_frequency` predictor. The ECP dataset, which we use for validation in Notebook 2, contains a wide vocabulary from many sources (general use, dictionaries, etc.). To create a comparable predictor, we must generate a corpus that is equally diverse. A simple corpus (e.g., only children's stories) is insufficient. This session focuses on generating a varied corpus to capture a broad slice of the English language."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec55856",
   "metadata": {},
   "source": [
    "## 1.1 Setup and API Configuration (10 minutes)\n",
    "\n",
    "Let's set up our environment and configure the API client to generate our corpus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f31d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Setup and API Configuration\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import re\n",
    "import time\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "print(\"🚀 LLM Text Generation Session\")\n",
    "print(\"=\" * 35)\n",
    "print(\"Setting up environment for corpus generation...\")\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"✅ Base environment configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0872fb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Configuration for Multiple LLM Services\n",
    "\n",
    "class LLMManager:\n",
    "    \"\"\"\n",
    "    Unified interface for multiple LLM APIs\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.apis = {\n",
    "            'deepseek': {\n",
    "                'endpoint': 'https://api.deepseek.com/v1/chat/completions',\n",
    "                'model': 'deepseek-chat',\n",
    "                'status': 'unconfigured'\n",
    "            },\n",
    "            'openai': {\n",
    "                'endpoint': 'https://api.openai.com/v1/chat/completions',\n",
    "                'model': 'gpt-3.5-turbo',\n",
    "                'status': 'unconfigured'\n",
    "            },\n",
    "            'groq': {\n",
    "                'endpoint': 'https://api.groq.com/openai/v1/chat/completions',\n",
    "                'model': 'llama3-8b-8192',\n",
    "                'status': 'unconfigured'\n",
    "            }\n",
    "        }\n",
    "        \n",
    "    def configure_api(self, service: str, api_key: str) -> bool:\n",
    "        \"\"\"\n",
    "        Configure API key for a specific service\n",
    "        \"\"\"\n",
    "        if service in self.apis:\n",
    "            self.apis[service]['api_key'] = api_key\n",
    "            self.apis[service]['status'] = 'configured'\n",
    "            print(f\"✅ {service.capitalize()} API configured\")\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def test_connection(self, service: str) -> bool:\n",
    "        \"\"\"\n",
    "        Test API connection with a simple request\n",
    "        \"\"\"\n",
    "        if self.apis[service]['status'] != 'configured':\n",
    "            print(f\"❌ {service.capitalize()} not configured\")\n",
    "            return False\n",
    "            \n",
    "        try:\n",
    "            # Simple test prompt\n",
    "            response = self.generate_text(\n",
    "                service=service,\n",
    "                prompt=\"Say 'API test successful' in one sentence.\",\n",
    "                max_tokens=20\n",
    "            )\n",
    "            if response and 'successful' in response.lower():\n",
    "                self.apis[service]['status'] = 'active'\n",
    "                print(f\"✅ {service.capitalize()} connection verified\")\n",
    "                return True\n",
    "        except Exception as e:\n",
    "            print(f\"❌ {service.capitalize()} connection failed: {str(e)[:50]}...\")\n",
    "            \n",
    "        return False\n",
    "    \n",
    "    def generate_text(self, service: str, prompt: str, max_tokens: int = 150, \n",
    "                     temperature: float = 0.7) -> str:\n",
    "        \"\"\"\n",
    "        Generate text using specified LLM service\n",
    "        \"\"\"\n",
    "        if self.apis[service]['status'] not in ['configured', 'active']:\n",
    "            raise ValueError(f\"{service} API not properly configured\")\n",
    "            \n",
    "        headers = {\n",
    "            'Authorization': f'Bearer {self.apis[service][\"api_key\"]}',\n",
    "            'Content-Type': 'application/json'\n",
    "        }\n",
    "        \n",
    "        data = {\n",
    "            'model': self.apis[service]['model'],\n",
    "            'messages': [\n",
    "                {'role': 'user', 'content': prompt}\n",
    "            ],\n",
    "            'max_tokens': max_tokens,\n",
    "            'temperature': temperature\n",
    "        }\n",
    "        \n",
    "        response = requests.post(\n",
    "            self.apis[service]['endpoint'],\n",
    "            headers=headers,\n",
    "            json=data,\n",
    "            timeout=30\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            return result['choices'][0]['message']['content'].strip()\n",
    "        else:\n",
    "            raise Exception(f\"API request failed: {response.status_code} - {response.text}\")\n",
    "    \n",
    "    def get_status(self) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Get status of all configured APIs\n",
    "        \"\"\"\n",
    "        return {service: config['status'] for service, config in self.apis.items()}\n",
    "\n",
    "# Initialize LLM manager\n",
    "llm_manager = LLMManager()\n",
    "\n",
    "print(\"🔧 LLM Manager initialized\")\n",
    "print(\"Available services: DeepSeek (free), OpenAI (premium), Groq (backup)\")\n",
    "print(\"\\n📝 Next: Configure your API keys below\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cac508d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Corpus Generation and Frequency Calculation ---\n",
    "\n",
    "# A diverse set of prompts to generate a representative corpus\n",
    "genre_prompts = {\n",
    "    \"Technical/Scientific\": [\n",
    "        \"Explain the process of photosynthesis in a way a high school student could understand.\",\n",
    "        \"Describe the basic principles of machine learning, including supervised and unsupervised learning.\",\n",
    "        \"Write a brief summary of the theory of plate tectonics and its importance in geology.\"\n",
    "    ],\n",
    "    \"News/Informative\": [\n",
    "        \"Write a short news report about the opening of a new public library in a small town.\",\n",
    "        \"Summarize the key findings of a recent study on the effects of remote work on employee productivity.\",\n",
    "        \"Create a brief article about the cultural significance of the Silk Road.\"\n",
    "    ],\n",
    "    \"Fiction/Creative\": [\n",
    "        \"Write the opening paragraph of a mystery novel set in a futuristic city.\",\n",
    "        \"Create a short story about a character who discovers a hidden world in their own backyard.\",\n",
    "        \"Write a descriptive scene of a bustling marketplace in a fantasy kingdom.\"\n",
    "    ],\n",
    "    \"General Knowledge/How-To\": [\n",
    "        \"Explain how to bake a simple loaf of bread, listing the ingredients and steps.\",\n",
    "        \"Write a short guide on the benefits of regular exercise for both physical and mental health.\",\n",
    "        \"Describe the rules of a classic card game like 'Hearts' or 'Rummy'.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "def generate_text_from_prompt(prompt: str, llm_manager, service: str) -> str:\n",
    "    \"\"\"Generates a text of about 200-300 words based on a prompt.\"\"\"\n",
    "    full_prompt = f\"Please write a clear and well-structured text of about 200-300 words based on the following instruction: {prompt}\"\n",
    "    try:\n",
    "        # Use the manager to generate text\n",
    "        return llm_manager.generate_text(\n",
    "            service=service,\n",
    "            prompt=full_prompt,\n",
    "            max_tokens=400,\n",
    "            temperature=0.7\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating text for prompt '{prompt[:30]}...': {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# 1. Generate the corpus if a service is active\n",
    "if 'primary_service' in globals() and primary_service:\n",
    "    print(f\"🚀 Generating diverse corpus using '{primary_service}'...\")\n",
    "    corpus_texts = []\n",
    "    for genre, prompts in genre_prompts.items():\n",
    "        print(f\"   - Generating texts for genre: {genre}\")\n",
    "        for p in prompts:\n",
    "            corpus_texts.append(generate_text_from_prompt(p, llm_manager, primary_service))\n",
    "            time.sleep(1) # Be respectful to the API\n",
    "    \n",
    "    full_corpus_text = \" \".join(corpus_texts)\n",
    "    print(\"✅ Corpus generation complete.\")\n",
    "\n",
    "    # 2. Calculate word frequencies\n",
    "    print(\"\\nCalculating word frequencies...\")\n",
    "    words = re.findall(r'\\\\b\\\\w+\\\\b', full_corpus_text.lower())\n",
    "    word_counts = Counter(words)\n",
    "    total_words = len(words)\n",
    "    llm_frequency = {word: count / total_words for word, count in word_counts.items()}\n",
    "    print(\"Frequency calculation complete.\")\n",
    "\n",
    "    # 3. Create a DataFrame and export\n",
    "    print(\"\\nCreating DataFrame and exporting to CSV...\")\n",
    "    freq_df = pd.DataFrame(list(llm_frequency.items()), columns=['word', 'llm_frequency'])\n",
    "    freq_df.to_csv('generated_frequency_predictors.csv', index=False)\n",
    "    print(\"✅ Export complete to 'generated_frequency_predictors.csv'\")\n",
    "\n",
    "    # Display the top 10 most frequent words\n",
    "    print(\"\\n--- Top 10 Most Frequent Words ---\")\n",
    "    print(freq_df.sort_values(by='llm_frequency', ascending=False).head(10))\n",
    "\n",
    "else:\n",
    "    print(\"⚠️ Cannot generate corpus. No active LLM service.\")\n",
    "    print(\"   Please configure an API key in the cell above and re-run.\")\n",
    "    # Create a dummy freq_df for demonstration if needed\n",
    "    freq_df = pd.DataFrame({'word': ['the', 'a', 'is'], 'llm_frequency': [0.1, 0.05, 0.04]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0810d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Key Configuration\n",
    "# 🔑 Configure your API keys here\n",
    "\n",
    "print(\"🔑 API Key Configuration\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "# Option 1: DeepSeek (Free tier available)\n",
    "# Get your free API key at: https://platform.deepseek.com/api_keys\n",
    "deepseek_key = \"\"  # Enter your DeepSeek API key\n",
    "\n",
    "# Option 2: OpenAI (Premium)\n",
    "# Get your API key at: https://platform.openai.com/api-keys\n",
    "openai_key = \"\"   # Enter your OpenAI API key\n",
    "\n",
    "# Option 3: Groq (Free tier available)\n",
    "# Get your API key at: https://console.groq.com/keys\n",
    "groq_key = \"\"     # Enter your Groq API key\n",
    "\n",
    "# Configure available services\n",
    "configured_services = []\n",
    "\n",
    "if deepseek_key:\n",
    "    llm_manager.configure_api('deepseek', deepseek_key)\n",
    "    configured_services.append('deepseek')\n",
    "\n",
    "if openai_key:\n",
    "    llm_manager.configure_api('openai', openai_key)\n",
    "    configured_services.append('openai')\n",
    "\n",
    "if groq_key:\n",
    "    llm_manager.configure_api('groq', groq_key)\n",
    "    configured_services.append('groq')\n",
    "\n",
    "if not configured_services:\n",
    "    print(\"⚠️ No API keys configured. Please add at least one API key above.\")\n",
    "    print(\"   Recommended: DeepSeek (free tier available)\")\n",
    "else:\n",
    "    print(f\"✅ Configured services: {', '.join(configured_services)}\")\n",
    "    \n",
    "    # Test connections\n",
    "    print(\"\\n🔍 Testing API connections...\")\n",
    "    active_services = []\n",
    "    \n",
    "    for service in configured_services:\n",
    "        if llm_manager.test_connection(service):\n",
    "            active_services.append(service)\n",
    "    \n",
    "    if active_services:\n",
    "        print(f\"\\n🎯 Ready for text generation with: {', '.join(active_services)}\")\n",
    "        primary_service = active_services[0]\n",
    "        print(f\"   Primary service: {primary_service}\")\n",
    "    else:\n",
    "        print(\"\\n❌ No working connections. Please check your API keys.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec163e2",
   "metadata": {},
   "source": [
    "## 1.2 Guided Text Generation (25 minutes)\n",
    "\n",
    "Now we'll systematically generate research corpus using different approaches and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a63936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Research-Oriented Text Generation Framework\n",
    "\n",
    "class CorpusGenerator:\n",
    "    \"\"\"\n",
    "    Systematic corpus generation for psycholinguistic research\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, llm_manager):\n",
    "        self.llm_manager = llm_manager\n",
    "        self.corpus_samples = {}\n",
    "        \n",
    "        # Research topics for diverse content\n",
    "        self.research_topics = [\n",
    "            \"environmental protection and sustainability\",\n",
    "            \"artificial intelligence and machine learning\", \n",
    "            \"climate change and global warming\",\n",
    "            \"renewable energy technologies\",\n",
    "            \"biodiversity conservation efforts\",\n",
    "            \"scientific research methodology\",\n",
    "            \"data analysis and statistics\",\n",
    "            \"educational technology development\"\n",
    "        ]\n",
    "    \n",
    "    def generate_systematic_corpus(self, service: str, num_samples: int = 4):\n",
    "        \"\"\"\n",
    "        Generate corpus with systematic parameter variation\n",
    "        \"\"\"\n",
    "        \n",
    "        print(f\"📝 Generating Systematic Corpus using {service.capitalize()}\")\n",
    "        print(\"-\" * 55)\n",
    "        \n",
    "        generation_configs = [\n",
    "            {'name': 'Formal Academic', 'temp': 0.3, 'style': 'formal academic language'},\n",
    "            {'name': 'General Informative', 'temp': 0.7, 'style': 'clear explanatory writing'},\n",
    "            {'name': 'Accessible Science', 'temp': 0.9, 'style': 'accessible science communication'},\n",
    "            {'name': 'Technical Detail', 'temp': 0.5, 'style': 'technical but readable style'}\n",
    "        ]\n",
    "        \n",
    "        for i, config in enumerate(generation_configs[:num_samples]):\n",
    "            topic = self.research_topics[i % len(self.research_topics)]\n",
    "            \n",
    "            prompt = f\"\"\"Write a 200-word informative text about {topic} using {config['style']}. \n",
    "            \n",
    "            Requirements:\n",
    "            - Focus on factual, educational content\n",
    "            - Use varied vocabulary and sentence structures\n",
    "            - Maintain scientific accuracy\n",
    "            - Write for educated general audience\n",
    "            \n",
    "            Topic: {topic.title()}\n",
    "            \"\"\"\n",
    "            \n",
    "            try:\n",
    "                print(f\"   Generating {config['name']} text (T={config['temp']})...\")\n",
    "                \n",
    "                text = self.llm_manager.generate_text(\n",
    "                    service=service,\n",
    "                    prompt=prompt,\n",
    "                    max_tokens=300,\n",
    "                    temperature=config['temp']\n",
    "                )\n",
    "                \n",
    "                self.corpus_samples[config['name']] = {\n",
    "                    'text': text,\n",
    "                    'topic': topic,\n",
    "                    'temperature': config['temp'],\n",
    "                    'style': config['style'],\n",
    "                    'word_count': len(text.split()),\n",
    "                    'service': service\n",
    "                }\n",
    "                \n",
    "                print(f\"   ✅ Generated {len(text.split())} words\")\n",
    "                \n",
    "                # Brief pause to be respectful to API\n",
    "                time.sleep(1)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   ❌ Failed to generate {config['name']}: {str(e)[:50]}...\")\n",
    "        \n",
    "        print(f\"\\n✅ Corpus generation complete: {len(self.corpus_samples)} samples\")\n",
    "        return self.corpus_samples\n",
    "    \n",
    "    def display_corpus_overview(self):\n",
    "        \"\"\"\n",
    "        Display overview of generated corpus\n",
    "        \"\"\"\n",
    "        \n",
    "        if not self.corpus_samples:\n",
    "            print(\"No corpus samples available.\")\n",
    "            return\n",
    "        \n",
    "        print(\"📊 Corpus Overview\")\n",
    "        print(\"=\" * 20)\n",
    "        \n",
    "        total_words = sum(sample['word_count'] for sample in self.corpus_samples.values())\n",
    "        \n",
    "        print(f\"   Total samples: {len(self.corpus_samples)}\")\n",
    "        print(f\"   Total words: {total_words:,}\")\n",
    "        print(f\"   Average words per sample: {total_words / len(self.corpus_samples):.1f}\")\n",
    "        \n",
    "        print(\"\\n📝 Sample Details:\")\n",
    "        for name, sample in self.corpus_samples.items():\n",
    "            print(f\"   {name}: {sample['word_count']} words (T={sample['temperature']})\")\n",
    "            print(f\"      Topic: {sample['topic']}\")\n",
    "            print(f\"      Preview: {sample['text'][:80]}...\")\n",
    "            print()\n",
    "\n",
    "# Initialize corpus generator\n",
    "corpus_gen = CorpusGenerator(llm_manager)\n",
    "\n",
    "print(\"🏗️ Corpus Generator initialized\")\n",
    "print(\"Ready to generate systematic research corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bbcaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the research corpus\n",
    "\n",
    "if 'primary_service' in globals():\n",
    "    print(\"🚀 Starting Corpus Generation\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    # Generate corpus using primary service\n",
    "    corpus_samples = corpus_gen.generate_systematic_corpus(primary_service, num_samples=4)\n",
    "    \n",
    "    # Display overview\n",
    "    corpus_gen.display_corpus_overview()\n",
    "    \n",
    "    # Save for use in next notebook\n",
    "    print(\"\\n💾 Saving corpus for analysis in Notebook 2...\")\n",
    "    \n",
    "else:\n",
    "    print(\"⚠️ No active LLM service available.\")\n",
    "    print(\"   Please configure API keys in the previous cell and run again.\")\n",
    "    \n",
    "    # Create sample data for demonstration\n",
    "    print(\"\\n🔄 Creating demonstration corpus...\")\n",
    "    corpus_samples = {\n",
    "        'Formal Academic': {\n",
    "            'text': \"Environmental protection represents a critical challenge requiring systematic approaches to sustainability. Research demonstrates that comprehensive conservation strategies must integrate technological innovation with policy frameworks. Scientific evidence indicates that immediate action is necessary to address climate change impacts. Effective environmental management requires interdisciplinary collaboration among researchers, policymakers, and community stakeholders.\",\n",
    "            'topic': 'environmental protection and sustainability',\n",
    "            'temperature': 0.3,\n",
    "            'style': 'formal academic language',\n",
    "            'word_count': 58,\n",
    "            'service': 'demo'\n",
    "        },\n",
    "        'General Informative': {\n",
    "            'text': \"Artificial intelligence is transforming how we approach complex problems across many fields. Machine learning algorithms can process vast amounts of data to identify patterns and make predictions that would be impossible for humans alone. These technologies are already helping doctors diagnose diseases, scientists discover new materials, and engineers design more efficient systems. As AI continues to develop, it promises to unlock solutions to some of our most pressing challenges.\",\n",
    "            'topic': 'artificial intelligence and machine learning',\n",
    "            'temperature': 0.7,\n",
    "            'style': 'clear explanatory writing',\n",
    "            'word_count': 72,\n",
    "            'service': 'demo'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    corpus_gen.corpus_samples = corpus_samples\n",
    "    corpus_gen.display_corpus_overview()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a04b7ed",
   "metadata": {},
   "source": [
    "## 1.3 Quality Assessment Framework (10 minutes)\n",
    "\n",
    "Now we'll assess the quality of our generated text and detect potential biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c091363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Quality Assessment Framework\n",
    "\n",
    "class QualityAssessment:\n",
    "    \"\"\"\n",
    "    Comprehensive quality assessment for generated text\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Bias detection word lists (simplified for demonstration)\n",
    "        self.bias_indicators = {\n",
    "            'gender': ['he', 'she', 'his', 'her', 'him', 'man', 'woman', 'male', 'female'],\n",
    "            'political': ['liberal', 'conservative', 'democrat', 'republican', 'progressive'],\n",
    "            'economic': ['rich', 'poor', 'wealthy', 'poverty', 'elite', 'class'],\n",
    "            'cultural': ['western', 'eastern', 'american', 'european', 'traditional', 'modern']\n",
    "        }\n",
    "        \n",
    "        self.quality_metrics = {}\n",
    "    \n",
    "    def assess_linguistic_quality(self, text: str) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Assess basic linguistic quality metrics\n",
    "        \"\"\"\n",
    "        \n",
    "        # Basic text statistics\n",
    "        words = text.lower().split()\n",
    "        sentences = text.split('.')\n",
    "        \n",
    "        # Remove empty sentences\n",
    "        sentences = [s.strip() for s in sentences if s.strip()]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        word_count = len(words)\n",
    "        sentence_count = len(sentences)\n",
    "        avg_words_per_sentence = word_count / max(sentence_count, 1)\n",
    "        \n",
    "        # Vocabulary richness (Type-Token Ratio)\n",
    "        unique_words = len(set(words))\n",
    "        ttr = unique_words / max(word_count, 1)\n",
    "        \n",
    "        # Average word length\n",
    "        avg_word_length = sum(len(word) for word in words) / max(word_count, 1)\n",
    "        \n",
    "        return {\n",
    "            'word_count': word_count,\n",
    "            'sentence_count': sentence_count,\n",
    "            'avg_words_per_sentence': avg_words_per_sentence,\n",
    "            'type_token_ratio': ttr,\n",
    "            'avg_word_length': avg_word_length,\n",
    "            'unique_words': unique_words\n",
    "        }\n",
    "    \n",
    "    def detect_bias_indicators(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Detect potential bias indicators in text\n",
    "        \"\"\"\n",
    "        \n",
    "        text_lower = text.lower()\n",
    "        words = text_lower.split()\n",
    "        \n",
    "        bias_detection = {}\n",
    "        \n",
    "        for bias_type, indicators in self.bias_indicators.items():\n",
    "            found_indicators = [word for word in indicators if word in text_lower]\n",
    "            \n",
    "            bias_detection[bias_type] = {\n",
    "                'indicators_found': found_indicators,\n",
    "                'count': len(found_indicators),\n",
    "                'density': len(found_indicators) / max(len(words), 1) * 100  # per 100 words\n",
    "            }\n",
    "        \n",
    "        return bias_detection\n",
    "    \n",
    "    def assess_content_appropriateness(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Assess content appropriateness for research use\n",
    "        \"\"\"\n",
    "        \n",
    "        # Check for scientific language indicators\n",
    "        scientific_terms = ['research', 'study', 'analysis', 'evidence', 'data', \n",
    "                          'method', 'results', 'findings', 'investigation', 'experiment']\n",
    "        \n",
    "        text_lower = text.lower()\n",
    "        scientific_count = sum(1 for term in scientific_terms if term in text_lower)\n",
    "        \n",
    "        # Check for problematic content indicators\n",
    "        problematic_terms = ['violence', 'hate', 'discrimination', 'controversial', \n",
    "                           'offensive', 'inappropriate']\n",
    "        \n",
    "        problematic_count = sum(1 for term in problematic_terms if term in text_lower)\n",
    "        \n",
    "        return {\n",
    "            'scientific_terms_count': scientific_count,\n",
    "            'scientific_density': scientific_count / max(len(text.split()), 1) * 100,\n",
    "            'problematic_terms_count': problematic_count,\n",
    "            'appropriateness_score': max(0, scientific_count - problematic_count * 2)  # Simple scoring\n",
    "        }\n",
    "    \n",
    "    def comprehensive_assessment(self, corpus_samples: Dict[str, Dict]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Run comprehensive quality assessment on entire corpus\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"🔍 Comprehensive Quality Assessment\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        assessment_results = {}\n",
    "        \n",
    "        for sample_name, sample_data in corpus_samples.items():\n",
    "            text = sample_data['text']\n",
    "            \n",
    "            print(f\"\\n📝 Assessing: {sample_name}\")\n",
    "            print(\"-\" * (15 + len(sample_name)))\n",
    "            \n",
    "            # Run all assessments\n",
    "            linguistic_quality = self.assess_linguistic_quality(text)\n",
    "            bias_detection = self.detect_bias_indicators(text)\n",
    "            content_appropriateness = self.assess_content_appropriateness(text)\n",
    "            \n",
    "            # Compile results\n",
    "            assessment_results[sample_name] = {\n",
    "                'linguistic_quality': linguistic_quality,\n",
    "                'bias_detection': bias_detection,\n",
    "                'content_appropriateness': content_appropriateness\n",
    "            }\n",
    "            \n",
    "            # Display key metrics\n",
    "            print(f\"   📊 Linguistic Quality:\")\n",
    "            print(f\"      Words: {linguistic_quality['word_count']}\")\n",
    "            print(f\"      Sentences: {linguistic_quality['sentence_count']}\")\n",
    "            print(f\"      Avg words/sentence: {linguistic_quality['avg_words_per_sentence']:.1f}\")\n",
    "            print(f\"      Vocabulary richness (TTR): {linguistic_quality['type_token_ratio']:.3f}\")\n",
    "            \n",
    "            print(f\"   🎯 Content Assessment:\")\n",
    "            print(f\"      Scientific terms: {content_appropriateness['scientific_terms_count']}\")\n",
    "            print(f\"      Appropriateness score: {content_appropriateness['appropriateness_score']}\")\n",
    "            \n",
    "            # Bias indicators summary\n",
    "            total_bias_indicators = sum(b['count'] for b in bias_detection.values())\n",
    "            print(f\"   ⚖️ Bias Indicators: {total_bias_indicators} total detected\")\n",
    "            \n",
    "            if total_bias_indicators > 0:\n",
    "                for bias_type, detection in bias_detection.items():\n",
    "                    if detection['count'] > 0:\n",
    "                        print(f\"      {bias_type.title()}: {detection['indicators_found']}\")\n",
    "            else:\n",
    "                print(f\"      ✅ No obvious bias indicators detected\")\n",
    "        \n",
    "        return assessment_results\n",
    "\n",
    "# Initialize quality assessment\n",
    "quality_assessor = QualityAssessment()\n",
    "\n",
    "print(\"🔧 Quality Assessment Framework initialized\")\n",
    "print(\"Ready to evaluate generated corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d889e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run quality assessment on generated corpus\n",
    "\n",
    "if 'corpus_samples' in globals() and corpus_samples:\n",
    "    # Run comprehensive assessment\n",
    "    assessment_results = quality_assessor.comprehensive_assessment(corpus_samples)\n",
    "    \n",
    "    print(\"\\n✅ Quality assessment complete!\")\n",
    "    \n",
    "    # Summary recommendations\n",
    "    print(\"\\n💡 Research Recommendations:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    total_words = sum(sample['word_count'] for sample in corpus_samples.values())\n",
    "    \n",
    "    if total_words > 200:\n",
    "        print(\"   ✅ Sufficient corpus size for preliminary analysis\")\n",
    "    else:\n",
    "        print(\"   ⚠️ Consider generating more text for robust analysis\")\n",
    "    \n",
    "    # Check vocabulary diversity\n",
    "    avg_ttr = np.mean([assessment_results[name]['linguistic_quality']['type_token_ratio'] \n",
    "                      for name in assessment_results.keys()])\n",
    "    \n",
    "    if avg_ttr > 0.6:\n",
    "        print(\"   ✅ Good vocabulary diversity across samples\")\n",
    "    else:\n",
    "        print(\"   ⚠️ Consider varying prompts for more lexical diversity\")\n",
    "    \n",
    "    # Check scientific content\n",
    "    avg_scientific = np.mean([assessment_results[name]['content_appropriateness']['appropriateness_score'] \n",
    "                             for name in assessment_results.keys()])\n",
    "    \n",
    "    if avg_scientific > 2:\n",
    "        print(\"   ✅ Appropriate scientific content for research use\")\n",
    "    else:\n",
    "        print(\"   ⚠️ Consider more research-focused prompts\")\n",
    "    \n",
    "    print(\"\\n🎯 Ready for Notebook 2: Corpus Analysis and Validation\")\n",
    "    \n",
    "else:\n",
    "    print(\"⚠️ No corpus available for assessment.\")\n",
    "    print(\"   Please generate corpus in previous cells first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d999c11",
   "metadata": {},
   "source": [
    "# 🎯 Session 4A Summary\n",
    "\n",
    "## What We've Accomplished\n",
    "\n",
    "✅ **API Configuration**: Set up multiple LLM services with robust error handling  \n",
    "✅ **Systematic Generation**: Created research corpus with controlled parameter variation  \n",
    "✅ **Quality Assessment**: Evaluated linguistic quality and detected potential biases  \n",
    "✅ **Research Preparation**: Generated corpus ready for psycholinguistic validation  \n",
    "\n",
    "## Key Learning Outcomes\n",
    "\n",
    "1. **LLM API Mastery**: Understanding of different services and their characteristics\n",
    "2. **Prompt Engineering**: Systematic approach to generating research-quality text\n",
    "3. **Quality Control**: Framework for assessing and validating generated content\n",
    "4. **Ethical Awareness**: Bias detection and content appropriateness evaluation\n",
    "\n",
    "## Ready for Notebook 2\n",
    "\n",
    "Our generated corpus is now ready for:\n",
    "- **Frequency Analysis**: Comparison with reference corpora (SUBTLEX, Multilex)\n",
    "- **Behavioral Validation**: Connection to human reading time databases\n",
    "- **Statistical Modeling**: Cubic splines regression and surprisal analysis\n",
    "- **Research Application**: Integration with established psycholinguistic methods\n",
    "\n",
    "---\n",
    "\n",
    "**Next**: Open **Notebook 2** to analyze our generated corpus and validate it against human behavioral data!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
